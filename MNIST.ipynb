{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMV0DF48HGRKqKWaKN45PUd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonghojo00/Pytorch/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBFFoVHdmSK4"
      },
      "source": [
        "Practice Notebook addressed in <https://youtu.be/GIsg-ZUy0MY>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrEklspDmRwN"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6dx2WCr54A",
        "outputId": "2135377b-7727-42ad-95eb-f1856ff99723"
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZp7R1Vlr_x2"
      },
      "source": [
        "# Change current directory\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Vision/MNIST')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XqJxIweruLs",
        "outputId": "4a403750-bea2-453f-b03d-bc8698f3503f"
      },
      "source": [
        "# Download training dataset (60000)\n",
        "dataset = MNIST(root='data/', download=True)\n",
        "print(len(dataset))\n",
        "print(dataset[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "(<PIL.Image.Image image mode=L size=28x28 at 0x7F6E39575E10>, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUSxIypksicK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FdYgAqEsPM5",
        "outputId": "9f0e2100-7462-4c8b-cadb-697b0d7c2b71"
      },
      "source": [
        "# Load test dataset (10000)\n",
        "test_dataset = MNIST(root='data/', train=False)\n",
        "len(test_dataset)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZRrH4ziseT7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# %matploblib inline is added to indicate that we weant to plot the graphs within the notebook. \n",
        "# Without this line, Colab will show the image in a popup. \n",
        "# Statements starting with % are called IPython magic commands and are used to configure the behavior of the environement itself."
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ALnOHqWFtK_U",
        "outputId": "73862c2d-5eca-48f4-ef97-f9cfc0d31993"
      },
      "source": [
        "image, label = dataset[0]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label: ', label)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "q14SLsn3t0jL",
        "outputId": "aa791fd3-ea80-4fb3-ca6e-159b35d91f4e"
      },
      "source": [
        "image, label = dataset[5]\n",
        "plt.imshow(image, cmap='gray')\n",
        "print('Label: ', label)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC4DJjDyuADj"
      },
      "source": [
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8ffwFAmuOpZ"
      },
      "source": [
        "# We will use ToTensor transform to convert images into PyTorch tensors\n",
        "# MNIST datset (images and labels)\n",
        "dataset = MNIST(root='data/',\n",
        "               train=True,\n",
        "               transform=transforms.ToTensor())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Al6d5jZufCi",
        "outputId": "d1ce957d-5548-43c8-ff35-40251fe6b7f8"
      },
      "source": [
        "img_tensor, label = dataset[0]\n",
        "print(img_tensor.shape, label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28]) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf11jLxJu8el"
      },
      "source": [
        "The image is now converted to 1x28x28 tensor. The first dimension is used to keep track of the clor channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7gA31zKuq_t",
        "outputId": "80d86558-c136-44aa-ebac-bdbaa6b869d2"
      },
      "source": [
        "print(img_tensor[:, 10:15, 10:15])\n",
        "print(torch.max(img_tensor), torch.min(img_tensor))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
            "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
            "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
            "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
            "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n",
            "tensor(1.) tensor(0.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA6yRPS6vbVO"
      },
      "source": [
        "'1' represents white and '0' represents black"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4If5deyGvSho"
      },
      "source": [
        "# Plot the image by passing in the 28x28 matrix"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "AyRD8QQjvmov",
        "outputId": "ccc5f110-eb28-4060-834b-107c3eb6e4e0"
      },
      "source": [
        "plt.imshow(img_tensor[0, 10:15, 10:15], cmap='gray')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e38fcd110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55lL_J7PT-46"
      },
      "source": [
        "# Training and Validation Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRC0dOoOW30q"
      },
      "source": [
        "### Split dataset into Training and Validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9eAK1XrW7Ty",
        "outputId": "190b0ac8-b0e3-4494-9bb9-ed593f36da15"
      },
      "source": [
        "# Select 20% of dataset to be validation set\n",
        "val_pct = 0.2\n",
        "n_train = int(len(dataset) * (1-val_pct))\n",
        "n_val = len(dataset) - n_train\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
        "print(\"Number of Training Dataset: \", len(train_set))\n",
        "print(\"Number of Validation Datset: \", len(val_set))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Training Dataset:  48000\n",
            "Number of Validation Datset:  12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAdxV7uqYJPA"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC4T3jSyY4Oi",
        "outputId": "ceef7a6c-5d5b-4c0a-9885-16be6e4d9436"
      },
      "source": [
        "len(train_loader)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLjYi1IsdYQr"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRRQD7q5e--y"
      },
      "source": [
        "Note that we have prepared our dataloaders, we can define our model\n",
        " * A logistic regression model is almost identital to a linear regression model. It contains weights and bias matrices. The output is obtained using a simple matrix operations ( Y_pred = x @ w.t() + b )\n",
        " * Since nn.Linear expects each training example to be a vector, each 1X28X28 image tensors is. lattened into a. ector of size 784 (28*28) before being passed into the. odel\n",
        " * The Output of each image is vector of. ize 10, with each element signifying the probability of.  particular target label (0 to 9). The predicted label for. ach image is simple the one with the highest probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgEtlqMJdfWz"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "input_size = 28*28\n",
        "num_classes = 10 #0 to 9"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh4RIFd8dkWq"
      },
      "source": [
        "# Logistic regression model\n",
        "# Linear(input_size, output_size)\n",
        "model = nn.Linear(input_size, num_classes)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSefSIwVg-FY",
        "outputId": "64b00f90-4264-4b04-fcf3-2bb68ab2cbb6"
      },
      "source": [
        "print(model.weight.shape)\n",
        "print(model.weight)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 784])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0093,  0.0123,  0.0100,  ...,  0.0070, -0.0333, -0.0061],\n",
            "        [ 0.0040, -0.0314, -0.0357,  ..., -0.0023, -0.0330, -0.0270],\n",
            "        [ 0.0179, -0.0326, -0.0151,  ..., -0.0028, -0.0030,  0.0132],\n",
            "        ...,\n",
            "        [-0.0096,  0.0191,  0.0267,  ..., -0.0317, -0.0160, -0.0266],\n",
            "        [-0.0271, -0.0266, -0.0219,  ...,  0.0240,  0.0169,  0.0056],\n",
            "        [-0.0332, -0.0113,  0.0014,  ..., -0.0104,  0.0024,  0.0261]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpyGLPLuhL9m",
        "outputId": "bfe5300d-a810-4941-b910-12916dfcb54c"
      },
      "source": [
        "print(model.bias.shape)\n",
        "print(model.bias)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n",
            "Parameter containing:\n",
            "tensor([ 0.0103,  0.0261, -0.0291, -0.0023,  0.0033,  0.0098,  0.0204, -0.0116,\n",
            "        -0.0039, -0.0297], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7CKiz7_hnLy",
        "outputId": "6f47d369-ded4-41e6-9b50-76f4dd387a55"
      },
      "source": [
        "train_loader"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f6e38f93210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "62RQrK52hTi1",
        "outputId": "ec68cb49-b544-42da-f321-462483fe2f2a"
      },
      "source": [
        "# Take the first batch of 100 images from our dataset, and pass them into our model\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    print(labels)\n",
        "    print(images.shape)\n",
        "    outputs = model(images)\n",
        "    break"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 9, 9, 0, 0, 4, 1, 6, 1, 8, 8, 3, 9, 8, 3, 7, 2, 1, 7, 1, 0, 2, 0, 0,\n",
            "        6, 6, 3, 6, 1, 3, 4, 3, 8, 2, 6, 6, 2, 0, 9, 0, 6, 2, 1, 1, 5, 3, 0, 7,\n",
            "        8, 0, 3, 8, 2, 2, 0, 4, 5, 1, 0, 6, 3, 0, 7, 4, 7, 7, 0, 8, 6, 2, 4, 4,\n",
            "        1, 4, 8, 0, 0, 5, 2, 7, 6, 7, 9, 5, 4, 8, 5, 7, 0, 2, 3, 1, 5, 5, 3, 5,\n",
            "        8, 3, 0, 6, 4, 8, 9, 2, 1, 2, 2, 2, 7, 6, 9, 7, 8, 3, 1, 6, 3, 5, 5, 3,\n",
            "        3, 2, 8, 8, 7, 8, 7, 2])\n",
            "torch.Size([128, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-2ddf887c04ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRnrMxaUik3w"
      },
      "source": [
        "It fails because the Model expects input of [128, 774] while the input was actually [128, 1, 28, 28].\n",
        "To flatten them out, we use .reshape method of a tensor, which will allow us to efficiently 'view' each image as a flat vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RM07RcFjHqS",
        "outputId": "b79a779d-ca58-4a79-d89f-b83b5215bd19"
      },
      "source": [
        "print(images.shape)\n",
        "print(images.reshape(128, 784).shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "torch.Size([128, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSm-nPxfii7L"
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() #What does do in torch to initiate a class\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "    def forward(self, xb): #xb: batch of input. At this time 128\n",
        "        xb = xb.reshape(-1, 784) # -1 enables to work with any batch size\n",
        "        out = self.linear(xb)\n",
        "        return out"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN72n2vijB44"
      },
      "source": [
        "model = MnistModel()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuzcPJcDlAy_",
        "outputId": "34dedbf6-38b0-4b43-843b-750c39f721eb"
      },
      "source": [
        "print(model.linear.weight.shape, model.linear.bias.shape)\n",
        "print(list(model.parameters()))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 784]) torch.Size([10])\n",
            "[Parameter containing:\n",
            "tensor([[-0.0230, -0.0250, -0.0136,  ...,  0.0008, -0.0315, -0.0184],\n",
            "        [ 0.0198,  0.0052,  0.0246,  ..., -0.0340,  0.0061,  0.0059],\n",
            "        [ 0.0156, -0.0196, -0.0200,  ...,  0.0214,  0.0166,  0.0135],\n",
            "        ...,\n",
            "        [ 0.0149,  0.0166, -0.0294,  ...,  0.0020,  0.0304,  0.0181],\n",
            "        [ 0.0122, -0.0340,  0.0354,  ...,  0.0205, -0.0335,  0.0352],\n",
            "        [-0.0248,  0.0034, -0.0153,  ..., -0.0314, -0.0100,  0.0189]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-4.1470e-03, -9.9272e-03,  5.8846e-03, -2.2289e-03, -7.5952e-03,\n",
            "         2.2352e-05,  1.9607e-02, -2.1767e-02, -8.1127e-03,  4.5652e-03],\n",
            "       requires_grad=True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqgDrO_Slxq6",
        "outputId": "8d8e4031-992b-429b-ce3f-8b16b8c1dae0"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "    print(images.shape)\n",
        "    outputs = model(images)\n",
        "    break\n",
        "\n",
        "print(\"Output shape: \", outputs.shape)\n",
        "print(\"Sample outputs: \\n\", outputs[:2].data) #Only printing out 2"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1, 28, 28])\n",
            "Output shape:  torch.Size([128, 10])\n",
            "Sample outputs: \n",
            " tensor([[ 0.1714,  0.1203, -0.3385, -0.1416, -0.0143, -0.0829, -0.0645,  0.0634,\n",
            "          0.0357, -0.1254],\n",
            "        [-0.4462, -0.0602, -0.1424, -0.0647, -0.3763, -0.0060, -0.0291,  0.0669,\n",
            "         -0.0524, -0.0335]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4dqV88imasM"
      },
      "source": [
        "We'd like these outputs to represent probabilities, but for that elements of each output row must lie between 0 to 1 and add up to 1, which is clearly not the case here.<br />\n",
        "To convert the output rows into probabilities, we use the softmax function\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQqAOdacmCgG"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skss2dsVpGfH",
        "outputId": "2acd34c0-7b0b-4d20-fc87-e9ee68fbf89d"
      },
      "source": [
        "# Apply softmax for each output row\n",
        "probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "# Look at sample probabilities\n",
        "print(\"Sample Probabilities: \\n\", probs[:2].data)\n",
        "\n",
        "# Add up the probabilities of an output row\n",
        "print(\"Sum: \", torch.sum(probs[0]).item())"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample Probabilities: \n",
            " tensor([[0.1221, 0.1160, 0.0733, 0.0893, 0.1014, 0.0947, 0.0964, 0.1096, 0.1066,\n",
            "         0.0907],\n",
            "        [0.0709, 0.1043, 0.0961, 0.1039, 0.0761, 0.1102, 0.1076, 0.1185, 0.1052,\n",
            "         0.1072]])\n",
            "Sum:  1.0000001192092896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbVaAjIxpKlR",
        "outputId": "2e454914-4fb3-4057-db14-ad0539016be2"
      },
      "source": [
        "max_probs, preds = torch.max(probs, dim=1)\n",
        "print(preds)\n",
        "print(max_probs)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 7, 7, 2, 5, 2, 2, 2, 7, 7, 9, 9, 6, 7, 7, 3, 2, 5, 1, 5, 8, 5, 2, 7,\n",
            "        7, 1, 9, 6, 5, 2, 9, 9, 9, 2, 9, 5, 5, 7, 0, 2, 5, 5, 8, 5, 3, 3, 6, 7,\n",
            "        9, 5, 2, 8, 5, 1, 2, 6, 7, 2, 6, 2, 5, 6, 7, 4, 9, 7, 2, 2, 2, 3, 7, 0,\n",
            "        6, 2, 4, 2, 9, 0, 6, 8, 0, 3, 7, 1, 8, 2, 2, 2, 6, 2, 3, 7, 6, 7, 2, 2,\n",
            "        6, 7, 5, 2, 8, 9, 2, 6, 0, 5, 2, 8, 3, 8, 3, 2, 0, 9, 7, 9, 2, 9, 6, 6,\n",
            "        2, 2, 6, 3, 6, 1, 9, 9])\n",
            "tensor([0.1221, 0.1185, 0.1163, 0.1203, 0.1295, 0.1448, 0.1574, 0.1146, 0.1204,\n",
            "        0.1213, 0.1175, 0.1132, 0.1359, 0.1199, 0.1398, 0.1333, 0.1252, 0.1278,\n",
            "        0.1247, 0.1259, 0.1152, 0.1211, 0.1312, 0.1222, 0.1251, 0.1282, 0.1144,\n",
            "        0.1272, 0.1332, 0.1283, 0.1147, 0.1079, 0.1294, 0.1270, 0.1242, 0.1193,\n",
            "        0.1233, 0.1220, 0.1163, 0.1369, 0.1207, 0.1288, 0.1157, 0.1236, 0.1257,\n",
            "        0.1216, 0.1189, 0.1135, 0.1228, 0.1273, 0.1203, 0.1125, 0.1173, 0.1256,\n",
            "        0.1130, 0.1229, 0.1355, 0.1231, 0.1299, 0.1267, 0.1420, 0.1128, 0.1308,\n",
            "        0.1247, 0.1323, 0.1217, 0.1292, 0.1228, 0.1192, 0.1201, 0.1152, 0.1145,\n",
            "        0.1250, 0.1399, 0.1168, 0.1250, 0.1188, 0.1135, 0.1325, 0.1213, 0.1245,\n",
            "        0.1245, 0.1195, 0.1186, 0.1242, 0.1256, 0.1393, 0.1240, 0.1232, 0.1171,\n",
            "        0.1178, 0.1210, 0.1217, 0.1239, 0.1243, 0.1216, 0.1225, 0.1162, 0.1290,\n",
            "        0.1231, 0.1274, 0.1165, 0.1266, 0.1390, 0.1099, 0.1380, 0.1202, 0.1250,\n",
            "        0.1147, 0.1141, 0.1222, 0.1099, 0.1329, 0.1243, 0.1189, 0.1142, 0.1227,\n",
            "        0.1364, 0.1444, 0.1288, 0.1371, 0.1279, 0.1380, 0.1300, 0.1259, 0.1124,\n",
            "        0.1249, 0.1265], grad_fn=<MaxBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orsP67cIpn7S",
        "outputId": "63f6d2d9-3dae-4c0b-feb2-dcaa4894cf37"
      },
      "source": [
        "labels"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3, 1, 9, 7, 0, 5, 4, 7, 5, 5, 2, 2, 1, 3, 0, 6, 8, 8, 0, 8, 4, 6, 3,\n",
              "        8, 1, 6, 7, 0, 7, 1, 8, 4, 8, 5, 3, 9, 9, 0, 0, 8, 0, 8, 3, 3, 7, 7, 0,\n",
              "        8, 9, 5, 1, 7, 3, 2, 4, 7, 7, 9, 6, 7, 4, 8, 6, 2, 3, 9, 9, 3, 3, 9, 1,\n",
              "        7, 5, 4, 9, 6, 2, 7, 3, 1, 7, 1, 9, 7, 4, 0, 7, 4, 0, 8, 1, 4, 1, 0, 2,\n",
              "        5, 5, 4, 5, 9, 4, 6, 7, 1, 0, 0, 9, 5, 3, 3, 5, 6, 6, 2, 6, 0, 3, 3, 7,\n",
              "        6, 0, 9, 2, 6, 3, 8, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNkalpTpp0UI"
      },
      "source": [
        "# Evaluation Metrics and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WsQ2WnVp54D"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJXCfl7dqNsq",
        "outputId": "bb3799c9-5ca7-46ca-8f8d-e21604e45fd5"
      },
      "source": [
        "accuracy(outputs, labels)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1016)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhUP3pXfsWXW"
      },
      "source": [
        "While accuracy is a good way to measure model accuracy, it cannot be used for gradient descent because it is not differentiable. <br />\n",
        "A commonly used loss funciton for classification problems is a cross-entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0y9m7tPqsZE",
        "outputId": "0aa0d5db-f5f1-4884-a247-5c2978b38a56"
      },
      "source": [
        "outputs"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1714,  0.1203, -0.3385,  ...,  0.0634,  0.0357, -0.1254],\n",
              "        [-0.4462, -0.0602, -0.1424,  ...,  0.0669, -0.0524, -0.0335],\n",
              "        [ 0.0975,  0.1058, -0.2118,  ...,  0.1502, -0.0641, -0.0592],\n",
              "        ...,\n",
              "        [-0.0851,  0.1121,  0.0586,  ...,  0.0023, -0.1236,  0.0137],\n",
              "        [-0.2233,  0.1748, -0.0144,  ..., -0.1238,  0.1108,  0.2262],\n",
              "        [-0.0749, -0.1163,  0.0933,  ..., -0.0157, -0.3639,  0.2016]],\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0IlFNRDtXQf"
      },
      "source": [
        "loss_fn = F.cross_entropy"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QG17EkTtaNH",
        "outputId": "824765b9-0534-4365-ba98-a0d109e48ce7"
      },
      "source": [
        "# Loss for current batch of data\n",
        "\n",
        "loss = loss_fn(outputs, labels)\n",
        "print(loss)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.2994, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1oBlrt1xDyW"
      },
      "source": [
        "Since the cross entropy is the negative logarithm of the predicted probability of the correct label averaged over all training samples, one way to interpret the resulting number 2.33 is look at e^-2.33, whichi is around 0.1 as the predicted probability of the correct label, on average. <br />\n",
        "Lower the loss, better the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkKhGv2MxeaZ"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw3esWVAxf9I"
      },
      "source": [
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93Xhqd8xlFM"
      },
      "source": [
        "Parameters like batch size, learining rate, and optimizer need to be selected in advance while training machine learning models. Selecting the right parameters are critical to the experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_IN2q1Tuk_R"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5U9NiuguoTJ"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # Training Phase\n",
        "    for batch in train_loader:\n",
        "        # Generate predictions\n",
        "        # Calculate loss\n",
        "        # Compute loss\n",
        "        # Compute gradients\n",
        "        # Update weights\n",
        "        # Reset gradients\n",
        "    \n",
        "    # Validation Phase\n",
        "    for batch in val_loader:\n",
        "        # Generate predictions\n",
        "        # Calculate loss\n",
        "        # Calculate metrics (accuracy etc.)\n",
        "\n",
        "        # Log epoch, loss & metrics for inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0bNKACzx_qD"
      },
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
        "    # Calculate loss\n",
        "    preds = model(xb)\n",
        "    loss = loss_func(preds, yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        # Compute the gradients\n",
        "        loss.backward()\n",
        "        # Update paramters\n",
        "        opt.step()\n",
        "        # Reset gradients\n",
        "        opt.zero_grad()\n",
        "\n",
        "    metric_result = None\n",
        "    if metric is not None:\n",
        "        # Compute the metric\n",
        "        metric_result = metric(preds, yb)\n",
        "\n",
        "    '''return\n",
        "    loss.item(): single value inside loss tensor\n",
        "    len(xb): length of the batch\n",
        "    metric_result: metric result\n",
        "\n",
        "    '''\n",
        "    return loss.item(), len(xb), metric_result\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1x_3urAxSIY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate(model, loss_fn, valid_dl, metric=None):\n",
        "    '''Calculate the overall loss(and a metric) for Validation Set\n",
        "    Input: Model, Loss funciton, Valdation DataLoader, Accuracy\n",
        "    '''\n",
        "    with torch.no_grad(): # Gradient Descent is only done for Traning set\n",
        "        # Pass each batch through the model\n",
        "        results = [loss_batch(model, loss_fn, xb, yb, metric=metric)\n",
        "                  for xb, yb in valid_dl]\n",
        "        # Separate losses, counts and metrics\n",
        "        losses, nums, metrics = zip(*results)\n",
        "        # Total size of the datset (We keep track of batch size because the last batch size will not be the same as the previous ones)\n",
        "        total = np.sum(nums)\n",
        "        # Avg. loss across batches\n",
        "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
        "        avg_metric = None\n",
        "        if metric is not None:\n",
        "            # Avg. of metric across batches\n",
        "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
        "    return avg_loss, total, avg_metric"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkgksWOj3QWb"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1) #Take the maximum value\n",
        "    return torch.sum(preds == labels).item() / len(preds)\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV95i7Mt3yTZ",
        "outputId": "76919cca-201e-402a-990a-d36e24e3f702"
      },
      "source": [
        "val_loss, total, val_acc = evaluate(model, loss_fn, val_loader, metric=accuracy)\n",
        "print('Loss: {:.4f}, Accuracy: {:.4f}'.format(val_loss, val_acc))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.3168, Accuracy: 0.0828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf6xYA-1td5w"
      },
      "source": [
        "def fit(epochs, model, loss_fn, opt, train_loader, valid_loader, metric=None):\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        for xb, yb in train_loader:\n",
        "            loss, _, _ = loss_batch(model, loss_fn, xb, yb, opt)\n",
        "        # Evaluation\n",
        "        result = evaluate(model, loss_fn, valid_loader, metric)\n",
        "        val_loss, total, val_metric = result\n",
        "\n",
        "        # Print Progress\n",
        "        if metric is None:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, epochs, val_loss))\n",
        "        else:\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}, {}: {:.4f}'\n",
        "                  .format(epoch+1, epochs, val_loss, metric.__name__, val_metric))\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTefMpnswEEO"
      },
      "source": [
        "# Redefine model and optimizer\n",
        "model = MnistModel()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgheIaBpwI2D",
        "outputId": "783c8043-14a1-462e-eb78-09fe8bbbf79c"
      },
      "source": [
        "fit(5, model, F.cross_entropy, optimizer, train_loader, val_loader, accuracy)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 1.9509, accuracy: 0.6158\n",
            "Epoch [2/5], Loss: 1.6915, accuracy: 0.7254\n",
            "Epoch [3/5], Loss: 1.4954, accuracy: 0.7612\n",
            "Epoch [4/5], Loss: 1.3461, accuracy: 0.7817\n",
            "Epoch [5/5], Loss: 1.2305, accuracy: 0.7936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVES0AlIcSWO",
        "outputId": "a739a0e5-08a3-499b-db41-43c01df427d3"
      },
      "source": [
        "fit(10, model, F.cross_entropy, optimizer, train_loader, val_loader, accuracy)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 1.1392, accuracy: 0.8038\n",
            "Epoch [2/10], Loss: 1.0656, accuracy: 0.8102\n",
            "Epoch [3/10], Loss: 1.0052, accuracy: 0.8155\n",
            "Epoch [4/10], Loss: 0.9547, accuracy: 0.8196\n",
            "Epoch [5/10], Loss: 0.9119, accuracy: 0.8228\n",
            "Epoch [6/10], Loss: 0.8753, accuracy: 0.8267\n",
            "Epoch [7/10], Loss: 0.8434, accuracy: 0.8291\n",
            "Epoch [8/10], Loss: 0.8155, accuracy: 0.8317\n",
            "Epoch [9/10], Loss: 0.7908, accuracy: 0.8345\n",
            "Epoch [10/10], Loss: 0.7688, accuracy: 0.8368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF411MDdxITN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9691fa26-ab7a-40b0-8811-562fe7cce632"
      },
      "source": [
        "fit(10, model, F.cross_entropy, optimizer, train_loader, val_loader, accuracy)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.7491, accuracy: 0.8390\n",
            "Epoch [2/10], Loss: 0.7313, accuracy: 0.8406\n",
            "Epoch [3/10], Loss: 0.7151, accuracy: 0.8424\n",
            "Epoch [4/10], Loss: 0.7003, accuracy: 0.8445\n",
            "Epoch [5/10], Loss: 0.6867, accuracy: 0.8458\n",
            "Epoch [6/10], Loss: 0.6742, accuracy: 0.8471\n",
            "Epoch [7/10], Loss: 0.6627, accuracy: 0.8488\n",
            "Epoch [8/10], Loss: 0.6520, accuracy: 0.8505\n",
            "Epoch [9/10], Loss: 0.6420, accuracy: 0.8513\n",
            "Epoch [10/10], Loss: 0.6327, accuracy: 0.8521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-09y8hidF9P",
        "outputId": "4375af67-6109-49f9-8081-a2c0faf8d13f"
      },
      "source": [
        "fit(20, model, F.cross_entropy, optimizer, train_loader, val_loader, accuracy)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.6240, accuracy: 0.8533\n",
            "Epoch [2/20], Loss: 0.6159, accuracy: 0.8548\n",
            "Epoch [3/20], Loss: 0.6082, accuracy: 0.8558\n",
            "Epoch [4/20], Loss: 0.6010, accuracy: 0.8572\n",
            "Epoch [5/20], Loss: 0.5942, accuracy: 0.8581\n",
            "Epoch [6/20], Loss: 0.5877, accuracy: 0.8586\n",
            "Epoch [7/20], Loss: 0.5816, accuracy: 0.8597\n",
            "Epoch [8/20], Loss: 0.5758, accuracy: 0.8612\n",
            "Epoch [9/20], Loss: 0.5703, accuracy: 0.8622\n",
            "Epoch [10/20], Loss: 0.5650, accuracy: 0.8631\n",
            "Epoch [11/20], Loss: 0.5600, accuracy: 0.8632\n",
            "Epoch [12/20], Loss: 0.5552, accuracy: 0.8636\n",
            "Epoch [13/20], Loss: 0.5507, accuracy: 0.8642\n",
            "Epoch [14/20], Loss: 0.5463, accuracy: 0.8650\n",
            "Epoch [15/20], Loss: 0.5421, accuracy: 0.8652\n",
            "Epoch [16/20], Loss: 0.5381, accuracy: 0.8658\n",
            "Epoch [17/20], Loss: 0.5342, accuracy: 0.8664\n",
            "Epoch [18/20], Loss: 0.5305, accuracy: 0.8666\n",
            "Epoch [19/20], Loss: 0.5269, accuracy: 0.8674\n",
            "Epoch [20/20], Loss: 0.5235, accuracy: 0.8680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4TVP3iEd0C4"
      },
      "source": [
        "# Testing with individual images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjVIgXrkd3dP",
        "outputId": "79953d6a-50af-4e83-e39d-4991fc259333"
      },
      "source": [
        "# Define the test dataset\n",
        "test_dataset = MNIST(root='data/',\n",
        "                     train=False,\n",
        "                     transform=transforms.ToTensor())\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "xUcydYOwgGlz",
        "outputId": "1f92a550-1d3e-4235-fa13-029232f91128"
      },
      "source": [
        "img, label = test_dataset[0]\n",
        "print(\"Shape:\", img.shape)\n",
        "print(\"Label: \", label)\n",
        "plt.imshow(img[0], cmap='gray')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: torch.Size([1, 28, 28])\n",
            "Label:  7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6e34603a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhSi1Z52gOVi",
        "outputId": "4ee30496-30b3-4e68-8e62-4e13e1572620"
      },
      "source": [
        "img.unsqueeze(0).shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhNhIhmNgrEY"
      },
      "source": [
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0)\n",
        "    yb = model(xb)\n",
        "    _, preds = torch.max(yb, dim=1)\n",
        "    return preds[0].item()"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QnvdNoShbhy"
      },
      "source": [
        "img.squeeze simple adds another dimension at the beginning of the 1x28x28, making it a 1x1x28x28 tensor, which the model views as a batch containig a single image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "1f1MiKZohJnY",
        "outputId": "9a816213-e1f3-4ec9-e15b-3cae561bea38"
      },
      "source": [
        "img, label = test_dataset[0]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print(\"Label: \", label, \" , Predicted: \", predict_image(img, model))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  7  , Predicted:  7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "UmetsQfdhP1H",
        "outputId": "001aa6e7-aaf9-42f2-eb44-8191c557792f"
      },
      "source": [
        "img, label = test_dataset[10]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print(\"Label: \", label, \" , Predicted: \", predict_image(img, model))"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  0  , Predicted:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANpklEQVR4nO3df+hVdZ7H8dcrV/+xojJWtImdioimaPshIayt1TBDW1L5jyk0tWTYjwlmaIUNVxohBmzZaemvQslyF7dhSIdkWnJa+zVmhPZj1bSZLIxRvmVipVIwa773j+9x+I597+d+vffce26+nw/4cu8973vueXPp1Tn3fM7x44gQgBPfSU03AKA/CDuQBGEHkiDsQBKEHUjir/q5Mduc+gd6LCI82vKu9uy2r7P9e9s7bT/QzWcB6C13Os5ue5ykP0j6gaTdkjZJmhcR2wvrsGcHeqwXe/YrJe2MiA8j4k+Sfinppi4+D0APdRP2syT9ccTr3dWyv2B7ge3Ntjd3sS0AXer5CbqIWCZpmcRhPNCkbvbseySdPeL1d6plAAZQN2HfJOl82+fYniBprqS19bQFoG4dH8ZHxGHb90laJ2mcpBUR8W5tnQGoVcdDbx1tjN/sQM/15KIaAN8ehB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dcpm9EbM2bMaFl7/fXXi+tecMEFxfqsWbOK9RtuuKFYf+6554r1ko0bNxbrGzZs6PizM2LPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMIvrADj11FOL9VWrVhXr1157bcvaV199VVx3woQJxfrJJ59crPdSu96//PLLYv2ee+5pWXvmmWc66unboNUsrl1dVGN7l6SDkr6WdDgipnXzeQB6p44r6K6JiH01fA6AHuI3O5BEt2EPSb+1/abtBaO9wfYC25ttb+5yWwC60O1h/IyI2GP7ryW9YPu9iHh15BsiYpmkZRIn6IAmdbVnj4g91eNeSb+WdGUdTQGoX8dhtz3R9ilHn0v6oaRtdTUGoF4dj7PbPlfDe3Np+OfAf0XEz9usw2H8KB577LFi/a677urZtnfs2FGsf/rpp8X6gQMHOt62Pepw8J+1u1e+nYMHD7asXXXVVcV1t2zZ0tW2m1T7OHtEfCjpbzvuCEBfMfQGJEHYgSQIO5AEYQeSIOxAEtzi2gcXXXRRsf7yyy8X65MmTSrWd+/e3bJ22223FdfduXNnsf75558X64cOHSrWS046qbyvefDBB4v1xYsXF+vjxo1rWVuzZk1x3TvvvLNY/+yzz4r1JrUaemPPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMGVzH5xyyinFertx9HbXQjz88MMta+3G8Jt05MiRYn3JkiXFert/BnvhwoUta7Nnzy6uu2LFimK9m6mom8KeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4H72Ppg5c2ax/tJLLxXrTz31VLF+xx13HG9LKXzwwQcta+ecc05x3SeffLJYnz9/fkc99QP3swPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEtzP3gcPPfRQV+u/8cYbNXWSy7p161rW7r777uK606dPr7udxrXds9teYXuv7W0jlp1h+wXb71ePp/e2TQDdGsth/FOSrjtm2QOS1kfE+ZLWV68BDLC2YY+IVyXtP2bxTZJWVs9XSrq55r4A1KzT3+yTI2Koev6xpMmt3mh7gaQFHW4HQE26PkEXEVG6wSUilklaJuW9EQYYBJ0OvX1ie4okVY9762sJQC90Gva1km6vnt8u6dl62gHQK20P420/LelqSWfa3i3pZ5KWSvqV7fmSPpI0p5dNDrpzzz23WJ86dWqx/sUXXxTrW7duPe6eIL344osta+3G2U9EbcMeEfNalL5fcy8AeojLZYEkCDuQBGEHkiDsQBKEHUiCW1xrcOuttxbr7YbmVq9eXaxv3LjxuHsCjsWeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9BnPnzi3W293C+uijj9bZDjAq9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7H3w3nvvFesbNmzoUyfIjD07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsYTZw4sWVt/PjxfewE6EzbPbvtFbb32t42YtkS23tsv1P9Xd/bNgF0ayyH8U9Jum6U5f8eEZdWf/9db1sA6tY27BHxqqT9fegFQA91c4LuPttbqsP801u9yfYC25ttb+5iWwC61GnYH5N0nqRLJQ1J+kWrN0bEsoiYFhHTOtwWgBp0FPaI+CQivo6II5KWS7qy3rYA1K2jsNueMuLlbEnbWr0XwGBoO85u+2lJV0s60/ZuST+TdLXtSyWFpF2S7uphjwNhzpw5LWvnnXdecd19+/bV3Q7G4MYbb+x43cOHD9fYyWBoG/aImDfK4id60AuAHuJyWSAJwg4kQdiBJAg7kARhB5LgFld8a11xxRXF+qxZszr+7EWLFnW87qBizw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOjoHVbhz9/vvvL9ZPO+20lrXXXnutuO66deuK9W8j9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GO0a9eulrWDBw/2r5ETyLhx44r1hQsXFuu33HJLsb5nz56OP/tE/Kek2bMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKOiP5tzO7fxvpo+/btxXq773jmzJnF+iBP+XzJJZcU6/fee2/L2uWXX15cd9q0aR31dNQ111zTsvbKK6909dmDLCI82vK2e3bbZ9t+yfZ22+/a/km1/AzbL9h+v3o8ve6mAdRnLIfxhyX9U0R8T9J0ST+2/T1JD0haHxHnS1pfvQYwoNqGPSKGIuKt6vlBSTsknSXpJkkrq7etlHRzr5oE0L3jujbe9nclXSbpDUmTI2KoKn0saXKLdRZIWtB5iwDqMOaz8bZPlrRa0k8j4sDIWgyfgRr1LFRELIuIaRHR3dkWAF0ZU9htj9dw0FdFxJpq8Se2p1T1KZL29qZFAHVoexhv25KekLQjIh4ZUVor6XZJS6vHZ3vS4QngwgsvLNaff/75Yn1oaKhYb9L06dOL9UmTJnX82e2GHNeuXVusb9q0qeNtn4jG8pv97yT9SNJW2+9UyxZpOOS/sj1f0keS5vSmRQB1aBv2iNggadRBeknfr7cdAL3C5bJAEoQdSIKwA0kQdiAJwg4kwS2uNZg9e3axvnjx4mL9sssuq7OdgXLkyJGWtf379xfXfeSRR4r1pUuXdtTTia7jW1wBnBgIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtn7YOrUqcV6u/vZL7744jrbqdXy5cuL9bfffrtl7fHHH6+7HYhxdiA9wg4kQdiBJAg7kARhB5Ig7EAShB1IgnF24ATDODuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJNE27LbPtv2S7e2237X9k2r5Ett7bL9T/V3f+3YBdKrtRTW2p0iaEhFv2T5F0puSbtbwfOyHIuLfxrwxLqoBeq7VRTVjmZ99SNJQ9fyg7R2Szqq3PQC9dly/2W1/V9Jlkt6oFt1ne4vtFbZPb7HOAtubbW/uqlMAXRnztfG2T5b0iqSfR8Qa25Ml7ZMUkh7S8KH+HW0+g8N4oMdaHcaPKey2x0v6jaR1EfGN2faqPf5vIqL4LyMSdqD3Or4RxrYlPSFpx8igVyfujpotaVu3TQLonbGcjZ8h6XeStko6Ov/uIknzJF2q4cP4XZLuqk7mlT6LPTvQY10dxteFsAO9x/3sQHKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJNr+g5M12yfpoxGvz6yWDaJB7W1Q+5LorVN19vY3rQp9vZ/9Gxu3N0fEtMYaKBjU3ga1L4neOtWv3jiMB5Ig7EASTYd9WcPbLxnU3ga1L4neOtWX3hr9zQ6gf5reswPoE8IOJNFI2G1fZ/v3tnfafqCJHlqxvcv21moa6kbnp6vm0Ntre9uIZWfYfsH2+9XjqHPsNdTbQEzjXZhmvNHvrunpz/v+m932OEl/kPQDSbslbZI0LyK297WRFmzvkjQtIhq/AMP230s6JOk/jk6tZftfJe2PiKXV/yhPj4h/HpDelug4p/HuUW+tphn/RzX43dU5/XknmtizXylpZ0R8GBF/kvRLSTc10MfAi4hXJe0/ZvFNklZWz1dq+D+WvmvR20CIiKGIeKt6flDS0WnGG/3uCn31RRNhP0vSH0e83q3Bmu89JP3W9pu2FzTdzCgmj5hm62NJk5tsZhRtp/Hup2OmGR+Y766T6c+7xQm6b5oREZdL+gdJP64OVwdSDP8GG6Sx08cknafhOQCHJP2iyWaqacZXS/ppRBwYWWvyuxulr758b02EfY+ks0e8/k61bCBExJ7qca+kX2v4Z8cg+eToDLrV496G+/mziPgkIr6OiCOSlqvB766aZny1pFURsaZa3Ph3N1pf/fremgj7Jknn2z7H9gRJcyWtbaCPb7A9sTpxItsTJf1QgzcV9VpJt1fPb5f0bIO9/IVBmca71TTjavi7a3z684jo+5+k6zV8Rv4DSf/SRA8t+jpX0v9Wf+823ZukpzV8WPd/Gj63MV/SJEnrJb0v6X8knTFAvf2nhqf23qLhYE1pqLcZGj5E3yLpnerv+qa/u0JfffneuFwWSIITdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8D0wdNeotu5ewAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "7b53CTUah8gg",
        "outputId": "1e545b4f-3892-4cfa-f465-b7d09f7c4f66"
      },
      "source": [
        "img, label = test_dataset[1839]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print(\"Label: \", label, \" , Predicted: \", predict_image(img, model))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label:  2  , Predicted:  8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UzaKGCRiEMU",
        "outputId": "cc72fd70-a104-4e10-c1f5-2802216354f4"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=200)\n",
        "\n",
        "test_loss, total, test_acc = evaluate(model, loss_fn, test_loader, metric=accuracy)\n",
        "print(\"Loss: {:.4f}, Accuracy: {:.4f}\".format(test_loss, test_acc))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.4928, Accuracy: 0.8817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg-_OSQ_iza3"
      },
      "source": [
        "The accuracy tends to increase as model runs more experiment and learns more"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta6sJEvMjYnS"
      },
      "source": [
        "# Save Model's Weight and Bias and Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbe6BNlrijWX"
      },
      "source": [
        "torch.save(model.state_dict(), 'mnist-logistic.pth')"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6d2OUJPi-Ff",
        "outputId": "4581f572-ce74-4fdc-ca50-c06ea352d6a2"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight',\n",
              "              tensor([[-0.0057,  0.0194, -0.0035,  ..., -0.0345,  0.0203, -0.0215],\n",
              "                      [ 0.0229,  0.0199, -0.0309,  ...,  0.0343,  0.0019,  0.0088],\n",
              "                      [-0.0189,  0.0003,  0.0177,  ...,  0.0112,  0.0049,  0.0354],\n",
              "                      ...,\n",
              "                      [-0.0317,  0.0273,  0.0081,  ...,  0.0192,  0.0351,  0.0250],\n",
              "                      [ 0.0064, -0.0075,  0.0067,  ...,  0.0049,  0.0332, -0.0005],\n",
              "                      [ 0.0176,  0.0275, -0.0304,  ..., -0.0184, -0.0110,  0.0285]])),\n",
              "             ('linear.bias',\n",
              "              tensor([-0.0808,  0.1278, -0.0508, -0.0537,  0.0729,  0.0640,  0.0175,  0.0624,\n",
              "                      -0.1853, -0.0317]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouksfD1ci_wk",
        "outputId": "810c3ee7-883c-4705-9b2e-46acd7fc8258"
      },
      "source": [
        "model2 = MnistModel()\n",
        "model2.load_state_dict(torch.load(\"mnist-logistic.pth\"))\n",
        "model2.state_dict()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear.weight',\n",
              "              tensor([[-0.0057,  0.0194, -0.0035,  ..., -0.0345,  0.0203, -0.0215],\n",
              "                      [ 0.0229,  0.0199, -0.0309,  ...,  0.0343,  0.0019,  0.0088],\n",
              "                      [-0.0189,  0.0003,  0.0177,  ...,  0.0112,  0.0049,  0.0354],\n",
              "                      ...,\n",
              "                      [-0.0317,  0.0273,  0.0081,  ...,  0.0192,  0.0351,  0.0250],\n",
              "                      [ 0.0064, -0.0075,  0.0067,  ...,  0.0049,  0.0332, -0.0005],\n",
              "                      [ 0.0176,  0.0275, -0.0304,  ..., -0.0184, -0.0110,  0.0285]])),\n",
              "             ('linear.bias',\n",
              "              tensor([-0.0808,  0.1278, -0.0508, -0.0537,  0.0729,  0.0640,  0.0175,  0.0624,\n",
              "                      -0.1853, -0.0317]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Loqsu6HjerZ",
        "outputId": "b189f6b5-34af-4eb4-e8dc-e03b1611f111"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=200)\n",
        "\n",
        "test_loss, total, test_acc = evaluate(model2, loss_fn, test_loader, metric=accuracy)\n",
        "print(\"Loss: {:.4f}, Accuracy: {:.4f}\".format(test_loss, test_acc))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.4928, Accuracy: 0.8817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJNkdynqjon-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}